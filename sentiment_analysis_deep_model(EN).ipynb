{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHmi1/smart-text-analysis-dj/blob/master/sentiment_analysis_deep_model(EN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKpdPx_-QwkZ",
        "outputId": "d9a53af2-9c18-421e-8944-6c46a3986634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 - Average Loss: 11.0308\n",
            "Epoch 2/2 - Average Loss: 10.7514\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine_tuned_model/tokenizer_config.json',\n",
              " './fine_tuned_model/special_tokens_map.json',\n",
              " './fine_tuned_model/vocab.json',\n",
              " './fine_tuned_model/merges.txt',\n",
              " './fine_tuned_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the BART tokenizer and model\n",
        "model_name = 'facebook/bart-base'\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Load the CNN/Daily Mail dataset (this may take a while if you're downloading it for the first time)\n",
        "dataset = load_dataset('cnn_dailymail', '3.0.0', split='train')\n",
        "\n",
        "# Get the source texts and summaries from the dataset\n",
        "source_texts = dataset['article'][:100]   # Using the first 1000 samples for demonstration\n",
        "summaries = dataset['highlights'][:100]   # Corresponding highlights are the abstractive summaries\n",
        "\n",
        "# Tokenize the source texts and summaries\n",
        "tokenized_inputs = tokenizer(source_texts, padding=True, truncation=True, return_tensors='pt')\n",
        "tokenized_targets = tokenizer(summaries, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Ensure inputs and targets have the same length\n",
        "assert len(tokenized_inputs['input_ids']) == len(tokenized_targets['input_ids'])\n",
        "\n",
        "# Prepare the DataLoader for faster training\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(tokenized_inputs['input_ids'], tokenized_inputs['attention_mask'],\n",
        "                              tokenized_targets['input_ids'], tokenized_targets['attention_mask'])\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Fine-tuning loop with transfer learning\n",
        "optimizer = AdamW(model.parameters(), lr=1e-7)\n",
        "num_epochs = 2\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch_inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'decoder_input_ids': batch[2],\n",
        "            'decoder_attention_mask': batch[3]\n",
        "        }\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(**batch_inputs, labels=batch_inputs['decoder_input_ids'])\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - Average Loss: {average_loss:.4f}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "output_model_dir = './fine_tuned_model/'\n",
        "model.save_pretrained(output_model_dir)\n",
        "tokenizer.save_pretrained(output_model_dir)\n",
        "\n",
        "# Rest of the code for summarization and website usage (unchanged)\n",
        "# ...\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "model_save_name = 'model.h5'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pKmsDYk0e0Y",
        "outputId": "479bb8fe-fbb8-4929-8c37-95262c016737"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnxA0o2drjKJHB1k1mAY8/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}